{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have our dataset in the form of .csv file finally\n",
    "### So now we need to train a CNN to predict the liveliness of the audio clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qjXHFNtNZ6su",
    "outputId": "f0e9179d-f800-41c4-84e1-2efd87d384f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization,Flatten,Activation,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we mounted the dataset in google drive into the colaboratory of google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "yQfJFe6qk7xG",
    "outputId": "5eb7ad23-b124-4f1e-d187-0f0c65753ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then we red the dataset in the form of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dWQx6zXaFiM"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gdrive/My Drive/ml_projects/data (1).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we load the numpy files of log-mel-spectrograms into 3 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuS0nTtGaFlv"
   },
   "outputs": [],
   "source": [
    "good_logmels = np.load(\"gdrive/My Drive/ml_projects/good_logmels (1).npy\")\n",
    "bad_logmels = np.load(\"gdrive/My Drive/ml_projects/bad_logmels (1).npy\")\n",
    "avg_logmels = np.load(\"gdrive/My Drive/ml_projects/avg_logmels (1).npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJ-AYjtZaFo_"
   },
   "outputs": [],
   "source": [
    "good_list = list(good_logmels)\n",
    "bad_list = list(bad_logmels)\n",
    "avg_list = list(avg_logmels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we concatenated the 3 lists of log-mel-specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1KMCEwV6aK21"
   },
   "outputs": [],
   "source": [
    "#convert the log mels to list of arrays\n",
    "logmels = good_list + bad_list + avg_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we add a new column to our dataframe that is 'logmels' to store log-mel-specs of each audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIQNgpEoaPL0"
   },
   "outputs": [],
   "source": [
    "data['logmels'] = logmels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeD6alh2aReZ"
   },
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "data = data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we split the dataset into 90% of training and 10% of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhU2BRT9aX1R"
   },
   "outputs": [],
   "source": [
    "#split into train and test(10%)\n",
    "training_data = data.iloc[:int(.9 * len(data))]\n",
    "testing_data = data.iloc[int(.9 * len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHPqqgc6aZPe"
   },
   "outputs": [],
   "source": [
    "def getXY(df):\n",
    "    X = np.stack(df.logmels)\n",
    "    X = X.reshape(len(df),128,216,1)\n",
    "    Y = np.array(df['class'])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Uua5uxoabGQ"
   },
   "outputs": [],
   "source": [
    "trainX,trainY = getXY(training_data)\n",
    "testX,testY = getXY(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we encode the labels good-bad-average into 0-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aewn4NERacn5"
   },
   "outputs": [],
   "source": [
    "#encode labels\n",
    "le = LabelEncoder()\n",
    "trainY = le.fit_transform(trainY)\n",
    "testY = le.fit_transform(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then we one hot encode the labels to bring them in binary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "3OcZ5OTFaezc",
    "outputId": "b350b68a-8957-4b55-fbb9-27217a95dfb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#one hot encode labels\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "trainY = ohe.fit_transform(trainY.reshape(len(trainY),1))\n",
    "testY = ohe.fit_transform(testY.reshape(len(testY),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we defined the architecture of our CNN, which we are going to use to train our model\n",
    "### first we put a convolution layer with 32 filters with each filter of size 5*5\n",
    "### the we put a Batchnormaliation layer\n",
    "### then we put an activation layer with 'relu' activation function\n",
    "### the we put a max pooling layer with pool size of 2*2\n",
    "### then convolutin layer with 64 filters\n",
    "### then batch normaliztin\n",
    "### then relu activation\n",
    "### then max pooling\n",
    "### then a Flatten layer to reshape the activation map into 1-d array\n",
    "### then a fully connected Dense layer with 128 neurons\n",
    "### then a batch normalization layer\n",
    "### then a activation layer with 'relu' activation\n",
    "### then a final output dense layer with 3 neurons and 'softmax' activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "9RZamweYagcG",
    "outputId": "22325f9a-935f-43aa-d95b-48d64f572ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "model = Sequential()\n",
    "#model.add(Dropout(0.2,input_shape = (128,216,1)))\n",
    "model.add(Conv2D(filters = 32,kernel_size = 5,strides = 2,input_shape = (128,216,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "          \n",
    "model.add(Conv2D(filters = 64,kernel_size = 5,strides = 2,input_shape = (128,216,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 3,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we compile our above defined cnn model with 'adam' optimizer\n",
    "### loss function used is 'categorical crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAbBUM0Faicy"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finally we trainined our model with batch size of 32,\n",
    "### and we held out 10% of validation data from training data\n",
    "### we saved best weights on the basis of validation accuracy at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12134
    },
    "colab_type": "code",
    "id": "AXkRXJMAakcg",
    "outputId": "5205a180-e512-4ed0-8019-1622786e9e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2583 samples, validate on 288 samples\n",
      "Epoch 1/500\n",
      "2583/2583 [==============================] - 6s 2ms/step - loss: 0.7189 - acc: 0.7096 - val_loss: 1.0355 - val_acc: 0.6146\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61458, saving model to try7-weights-improvement-01-0.61.hdf5\n",
      "Epoch 2/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 0.2857 - acc: 0.8966 - val_loss: 0.5905 - val_acc: 0.7326\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61458 to 0.73264, saving model to try7-weights-improvement-02-0.73.hdf5\n",
      "Epoch 3/500\n",
      "2583/2583 [==============================] - 2s 813us/step - loss: 0.1591 - acc: 0.9504 - val_loss: 0.5524 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73264 to 0.74653, saving model to try7-weights-improvement-03-0.75.hdf5\n",
      "Epoch 4/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 0.0644 - acc: 0.9845 - val_loss: 2.0732 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.74653\n",
      "Epoch 5/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 0.0486 - acc: 0.9907 - val_loss: 0.4147 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74653 to 0.83681, saving model to try7-weights-improvement-05-0.84.hdf5\n",
      "Epoch 6/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 0.0248 - acc: 0.9969 - val_loss: 1.3883 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.83681\n",
      "Epoch 7/500\n",
      "2583/2583 [==============================] - 2s 817us/step - loss: 0.0205 - acc: 0.9965 - val_loss: 0.3204 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.83681 to 0.89236, saving model to try7-weights-improvement-07-0.89.hdf5\n",
      "Epoch 8/500\n",
      "2583/2583 [==============================] - 2s 829us/step - loss: 0.0136 - acc: 0.9981 - val_loss: 0.4566 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89236\n",
      "Epoch 9/500\n",
      "2583/2583 [==============================] - 2s 829us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.7134 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89236\n",
      "Epoch 10/500\n",
      "2583/2583 [==============================] - 2s 822us/step - loss: 0.0049 - acc: 0.9996 - val_loss: 0.2758 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89236\n",
      "Epoch 11/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 0.0063 - acc: 0.9996 - val_loss: 0.4037 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89236\n",
      "Epoch 12/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.7620 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89236\n",
      "Epoch 13/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 0.0384 - acc: 0.9884 - val_loss: 0.8875 - val_acc: 0.7431\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.89236\n",
      "Epoch 14/500\n",
      "2583/2583 [==============================] - 2s 800us/step - loss: 0.0971 - acc: 0.9644 - val_loss: 2.4187 - val_acc: 0.6007\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.89236\n",
      "Epoch 15/500\n",
      "2583/2583 [==============================] - 2s 806us/step - loss: 0.0719 - acc: 0.9741 - val_loss: 0.4239 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.89236\n",
      "Epoch 16/500\n",
      "2583/2583 [==============================] - 2s 792us/step - loss: 0.0187 - acc: 0.9961 - val_loss: 0.5558 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.89236\n",
      "Epoch 17/500\n",
      "2583/2583 [==============================] - 2s 805us/step - loss: 0.0167 - acc: 0.9965 - val_loss: 0.4614 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.89236\n",
      "Epoch 18/500\n",
      "2583/2583 [==============================] - 2s 799us/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.4828 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.89236\n",
      "Epoch 19/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2254 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.89236 to 0.93750, saving model to try7-weights-improvement-19-0.94.hdf5\n",
      "Epoch 20/500\n",
      "2583/2583 [==============================] - 2s 806us/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.3441 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93750\n",
      "Epoch 21/500\n",
      "2583/2583 [==============================] - 2s 816us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.2170 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93750\n",
      "Epoch 22/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.5538 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93750\n",
      "Epoch 23/500\n",
      "2583/2583 [==============================] - 2s 806us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3783 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93750\n",
      "Epoch 24/500\n",
      "2583/2583 [==============================] - 2s 797us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.2652 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93750\n",
      "Epoch 25/500\n",
      "2583/2583 [==============================] - 2s 812us/step - loss: 9.2060e-04 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93750\n",
      "Epoch 26/500\n",
      "2583/2583 [==============================] - 2s 806us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2175 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93750\n",
      "Epoch 27/500\n",
      "2583/2583 [==============================] - 2s 804us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.93750\n",
      "Epoch 28/500\n",
      "2583/2583 [==============================] - 2s 815us/step - loss: 6.4839e-04 - acc: 1.0000 - val_loss: 0.2268 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93750\n",
      "Epoch 29/500\n",
      "2583/2583 [==============================] - 2s 825us/step - loss: 6.6496e-04 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93750\n",
      "Epoch 30/500\n",
      "2583/2583 [==============================] - 2s 821us/step - loss: 6.4287e-04 - acc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.93750 to 0.95486, saving model to try7-weights-improvement-30-0.95.hdf5\n",
      "Epoch 31/500\n",
      "2583/2583 [==============================] - 2s 821us/step - loss: 5.8811e-04 - acc: 1.0000 - val_loss: 0.2081 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.95486\n",
      "Epoch 32/500\n",
      "2583/2583 [==============================] - 2s 822us/step - loss: 5.1944e-04 - acc: 1.0000 - val_loss: 0.2159 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.95486\n",
      "Epoch 33/500\n",
      "2583/2583 [==============================] - 2s 821us/step - loss: 4.5341e-04 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.95486\n",
      "Epoch 34/500\n",
      "2583/2583 [==============================] - 2s 822us/step - loss: 2.7923e-04 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.95486\n",
      "Epoch 35/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 3.7625e-04 - acc: 1.0000 - val_loss: 0.2167 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.95486\n",
      "Epoch 36/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 2.3941e-04 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.95486\n",
      "Epoch 37/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 1.9939e-04 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.95486\n",
      "Epoch 38/500\n",
      "2583/2583 [==============================] - 2s 815us/step - loss: 3.2130e-04 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.95486\n",
      "Epoch 39/500\n",
      "2583/2583 [==============================] - 2s 801us/step - loss: 2.2036e-04 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.95486\n",
      "Epoch 40/500\n",
      "2583/2583 [==============================] - 2s 804us/step - loss: 2.5240e-04 - acc: 1.0000 - val_loss: 0.2210 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.95486\n",
      "Epoch 41/500\n",
      "2583/2583 [==============================] - 2s 811us/step - loss: 4.4314e-04 - acc: 1.0000 - val_loss: 0.2100 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.95486\n",
      "Epoch 42/500\n",
      "2583/2583 [==============================] - 2s 800us/step - loss: 1.7522e-04 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.95486\n",
      "Epoch 43/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 2.6063e-04 - acc: 1.0000 - val_loss: 0.3525 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.95486\n",
      "Epoch 44/500\n",
      "2583/2583 [==============================] - 2s 813us/step - loss: 3.6607e-04 - acc: 1.0000 - val_loss: 0.4592 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.95486\n",
      "Epoch 45/500\n",
      "2583/2583 [==============================] - 2s 802us/step - loss: 0.0484 - acc: 0.9845 - val_loss: 5.4213 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.95486\n",
      "Epoch 46/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 0.2513 - acc: 0.9059 - val_loss: 4.9157 - val_acc: 0.5590\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.95486\n",
      "Epoch 47/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 0.0571 - acc: 0.9806 - val_loss: 0.4007 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.95486\n",
      "Epoch 48/500\n",
      "2583/2583 [==============================] - 2s 811us/step - loss: 0.0215 - acc: 0.9942 - val_loss: 0.4535 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.95486\n",
      "Epoch 49/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 0.0092 - acc: 0.9981 - val_loss: 0.8686 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.95486\n",
      "Epoch 50/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 0.0146 - acc: 0.9961 - val_loss: 0.4157 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.95486\n",
      "Epoch 51/500\n",
      "2583/2583 [==============================] - 2s 804us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2734 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.95486\n",
      "Epoch 52/500\n",
      "2583/2583 [==============================] - 2s 796us/step - loss: 0.0045 - acc: 0.9992 - val_loss: 0.6142 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.95486\n",
      "Epoch 53/500\n",
      "2583/2583 [==============================] - 2s 798us/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.2675 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.95486\n",
      "Epoch 54/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2398 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.95486\n",
      "Epoch 55/500\n",
      "2583/2583 [==============================] - 2s 816us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.3960 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.95486\n",
      "Epoch 56/500\n",
      "2583/2583 [==============================] - 2s 806us/step - loss: 9.3690e-04 - acc: 1.0000 - val_loss: 0.2311 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.95486\n",
      "Epoch 57/500\n",
      "2583/2583 [==============================] - 2s 823us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2581 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.95486\n",
      "Epoch 58/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 8.0743e-04 - acc: 1.0000 - val_loss: 0.2203 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.95486\n",
      "Epoch 59/500\n",
      "2583/2583 [==============================] - 2s 803us/step - loss: 5.2018e-04 - acc: 1.0000 - val_loss: 0.2452 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.95486\n",
      "Epoch 60/500\n",
      "2583/2583 [==============================] - 2s 799us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6983 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.95486\n",
      "Epoch 61/500\n",
      "2583/2583 [==============================] - 2s 804us/step - loss: 9.8601e-04 - acc: 1.0000 - val_loss: 0.2386 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.95486\n",
      "Epoch 62/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2198 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.95486\n",
      "Epoch 63/500\n",
      "2583/2583 [==============================] - 2s 799us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.4786 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.95486\n",
      "Epoch 64/500\n",
      "2583/2583 [==============================] - 2s 793us/step - loss: 0.0103 - acc: 0.9973 - val_loss: 3.0003 - val_acc: 0.6007\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.95486\n",
      "Epoch 65/500\n",
      "2583/2583 [==============================] - 2s 793us/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.4663 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.95486\n",
      "Epoch 66/500\n",
      "2583/2583 [==============================] - 2s 805us/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.5947 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.95486\n",
      "Epoch 67/500\n",
      "2583/2583 [==============================] - 2s 802us/step - loss: 0.0416 - acc: 0.9845 - val_loss: 1.5175 - val_acc: 0.7326\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.95486\n",
      "Epoch 68/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 0.0224 - acc: 0.9919 - val_loss: 1.2610 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.95486\n",
      "Epoch 69/500\n",
      "2583/2583 [==============================] - 2s 795us/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.5228 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.95486\n",
      "Epoch 70/500\n",
      "2583/2583 [==============================] - 2s 803us/step - loss: 0.0103 - acc: 0.9954 - val_loss: 0.8478 - val_acc: 0.8056\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.95486\n",
      "Epoch 71/500\n",
      "2583/2583 [==============================] - 2s 803us/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.9604 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.95486\n",
      "Epoch 72/500\n",
      "2583/2583 [==============================] - 2s 797us/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.3320 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.95486\n",
      "Epoch 73/500\n",
      "2583/2583 [==============================] - 2s 802us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2259 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.95486\n",
      "Epoch 74/500\n",
      "2583/2583 [==============================] - 2s 803us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.3333 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.95486\n",
      "Epoch 75/500\n",
      "2583/2583 [==============================] - 2s 802us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2145 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.95486\n",
      "Epoch 76/500\n",
      "2583/2583 [==============================] - 2s 793us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2965 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.95486\n",
      "Epoch 77/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.95486\n",
      "Epoch 78/500\n",
      "2583/2583 [==============================] - 2s 801us/step - loss: 9.5813e-04 - acc: 0.9996 - val_loss: 0.2651 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.95486\n",
      "Epoch 79/500\n",
      "2583/2583 [==============================] - 2s 803us/step - loss: 0.0040 - acc: 0.9992 - val_loss: 1.9839 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.95486\n",
      "Epoch 80/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.2906 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.95486\n",
      "Epoch 81/500\n",
      "2583/2583 [==============================] - 2s 797us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3251 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.95486\n",
      "Epoch 82/500\n",
      "2583/2583 [==============================] - 2s 794us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.2124 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.95486\n",
      "Epoch 83/500\n",
      "2583/2583 [==============================] - 2s 800us/step - loss: 5.5875e-04 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.95486\n",
      "Epoch 84/500\n",
      "2583/2583 [==============================] - 2s 801us/step - loss: 5.3261e-04 - acc: 1.0000 - val_loss: 0.2650 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.95486\n",
      "Epoch 85/500\n",
      "2583/2583 [==============================] - 2s 812us/step - loss: 8.3371e-04 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.95486\n",
      "Epoch 86/500\n",
      "2583/2583 [==============================] - 2s 813us/step - loss: 5.0375e-04 - acc: 1.0000 - val_loss: 0.1949 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.95486\n",
      "Epoch 87/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 2.5654e-04 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.95486 to 0.96181, saving model to try7-weights-improvement-87-0.96.hdf5\n",
      "Epoch 88/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 2.4916e-04 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.96181\n",
      "Epoch 89/500\n",
      "2583/2583 [==============================] - 2s 801us/step - loss: 2.0045e-04 - acc: 1.0000 - val_loss: 0.1852 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.96181\n",
      "Epoch 90/500\n",
      "2583/2583 [==============================] - 2s 801us/step - loss: 1.9579e-04 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.96181\n",
      "Epoch 91/500\n",
      "2583/2583 [==============================] - 2s 814us/step - loss: 1.5723e-04 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.96181\n",
      "Epoch 92/500\n",
      "2583/2583 [==============================] - 2s 813us/step - loss: 0.0037 - acc: 0.9985 - val_loss: 1.0545 - val_acc: 0.7951\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.96181\n",
      "Epoch 93/500\n",
      "2583/2583 [==============================] - 2s 805us/step - loss: 0.0326 - acc: 0.9903 - val_loss: 1.7352 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.96181\n",
      "Epoch 94/500\n",
      "2583/2583 [==============================] - 2s 806us/step - loss: 0.0430 - acc: 0.9849 - val_loss: 1.4950 - val_acc: 0.7639\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.96181\n",
      "Epoch 95/500\n",
      "2583/2583 [==============================] - 2s 805us/step - loss: 0.0208 - acc: 0.9926 - val_loss: 0.2791 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.96181\n",
      "Epoch 96/500\n",
      "2583/2583 [==============================] - 2s 800us/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.8280 - val_acc: 0.8021\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.96181\n",
      "Epoch 97/500\n",
      "2583/2583 [==============================] - 2s 832us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.96181\n",
      "Epoch 98/500\n",
      "2583/2583 [==============================] - 2s 832us/step - loss: 0.0029 - acc: 0.9996 - val_loss: 1.0165 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.96181\n",
      "Epoch 99/500\n",
      "2583/2583 [==============================] - 2s 824us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.2481 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.96181\n",
      "Epoch 100/500\n",
      "2583/2583 [==============================] - 2s 794us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.5423 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.96181\n",
      "Epoch 101/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 8.6354e-04 - acc: 1.0000 - val_loss: 0.2471 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.96181\n",
      "Epoch 102/500\n",
      "2583/2583 [==============================] - 2s 798us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2790 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.96181\n",
      "Epoch 103/500\n",
      "2583/2583 [==============================] - 2s 798us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3579 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.96181\n",
      "Epoch 104/500\n",
      "2583/2583 [==============================] - 2s 811us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.9540 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.96181\n",
      "Epoch 105/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 0.0091 - acc: 0.9977 - val_loss: 1.6587 - val_acc: 0.6910\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.96181\n",
      "Epoch 106/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.2633 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.96181\n",
      "Epoch 107/500\n",
      "2583/2583 [==============================] - 2s 802us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.2724 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.96181\n",
      "Epoch 108/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.2157 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.96181\n",
      "Epoch 109/500\n",
      "2583/2583 [==============================] - 2s 831us/step - loss: 0.0031 - acc: 0.9988 - val_loss: 1.3755 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.96181\n",
      "Epoch 110/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.2769 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.96181\n",
      "Epoch 111/500\n",
      "2583/2583 [==============================] - 2s 827us/step - loss: 6.2886e-04 - acc: 1.0000 - val_loss: 0.2890 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.96181\n",
      "Epoch 112/500\n",
      "2583/2583 [==============================] - 2s 827us/step - loss: 5.1583e-04 - acc: 1.0000 - val_loss: 0.3417 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.96181\n",
      "Epoch 113/500\n",
      "2583/2583 [==============================] - 2s 823us/step - loss: 5.8898e-04 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.96181\n",
      "Epoch 114/500\n",
      "2583/2583 [==============================] - 2s 823us/step - loss: 7.5522e-04 - acc: 1.0000 - val_loss: 0.3166 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.96181\n",
      "Epoch 115/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 1.1998 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.96181\n",
      "Epoch 116/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.3572 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.96181\n",
      "Epoch 117/500\n",
      "2583/2583 [==============================] - 2s 827us/step - loss: 6.5803e-04 - acc: 1.0000 - val_loss: 0.9363 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.96181\n",
      "Epoch 118/500\n",
      "2583/2583 [==============================] - 2s 825us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.3618 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.96181\n",
      "Epoch 119/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.8853 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.96181\n",
      "Epoch 120/500\n",
      "2583/2583 [==============================] - 2s 812us/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.9767 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.96181\n",
      "Epoch 121/500\n",
      "2583/2583 [==============================] - 2s 803us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 1.3791 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.96181\n",
      "Epoch 122/500\n",
      "2583/2583 [==============================] - 2s 807us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.5303 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.96181\n",
      "Epoch 123/500\n",
      "2583/2583 [==============================] - 2s 814us/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.5526 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.96181\n",
      "Epoch 124/500\n",
      "2583/2583 [==============================] - 2s 825us/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.5310 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.96181\n",
      "Epoch 125/500\n",
      "2583/2583 [==============================] - 2s 812us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3677 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.96181\n",
      "Epoch 126/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.6250 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.96181\n",
      "Epoch 127/500\n",
      "2583/2583 [==============================] - 2s 811us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3577 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.96181\n",
      "Epoch 128/500\n",
      "2583/2583 [==============================] - 2s 813us/step - loss: 4.3807e-04 - acc: 1.0000 - val_loss: 0.2699 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.96181\n",
      "Epoch 129/500\n",
      "2583/2583 [==============================] - 2s 814us/step - loss: 4.4000e-04 - acc: 1.0000 - val_loss: 0.3751 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.96181\n",
      "Epoch 130/500\n",
      "2583/2583 [==============================] - 2s 818us/step - loss: 0.0058 - acc: 0.9977 - val_loss: 0.7702 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.96181\n",
      "Epoch 131/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.7245 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.96181\n",
      "Epoch 132/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 0.0029 - acc: 0.9988 - val_loss: 0.6160 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.96181\n",
      "Epoch 133/500\n",
      "2583/2583 [==============================] - 2s 814us/step - loss: 0.0072 - acc: 0.9961 - val_loss: 4.2803 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.96181\n",
      "Epoch 134/500\n",
      "2583/2583 [==============================] - 2s 824us/step - loss: 0.0063 - acc: 0.9973 - val_loss: 0.4803 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.96181\n",
      "Epoch 135/500\n",
      "2583/2583 [==============================] - 2s 818us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.6255 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.96181\n",
      "Epoch 136/500\n",
      "2583/2583 [==============================] - 2s 809us/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.4304 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.96181\n",
      "Epoch 137/500\n",
      "2583/2583 [==============================] - 2s 816us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.3730 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.96181\n",
      "Epoch 138/500\n",
      "2583/2583 [==============================] - 2s 810us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 1.8048 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.96181\n",
      "Epoch 139/500\n",
      "2583/2583 [==============================] - 2s 818us/step - loss: 0.0096 - acc: 0.9957 - val_loss: 3.6787 - val_acc: 0.6007\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.96181\n",
      "Epoch 140/500\n",
      "2583/2583 [==============================] - 2s 818us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.5067 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.96181\n",
      "Epoch 141/500\n",
      "2583/2583 [==============================] - 2s 844us/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.2898 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.96181\n",
      "Epoch 142/500\n",
      "2583/2583 [==============================] - 2s 833us/step - loss: 9.2530e-04 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.96181\n",
      "Epoch 143/500\n",
      "2583/2583 [==============================] - 2s 832us/step - loss: 7.1101e-04 - acc: 1.0000 - val_loss: 0.2785 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.96181\n",
      "Epoch 144/500\n",
      "2583/2583 [==============================] - 2s 838us/step - loss: 6.5395e-04 - acc: 1.0000 - val_loss: 0.3636 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.96181\n",
      "Epoch 145/500\n",
      "2583/2583 [==============================] - 2s 840us/step - loss: 5.5309e-04 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.96181\n",
      "Epoch 146/500\n",
      "2583/2583 [==============================] - 2s 833us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 1.0483 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.96181\n",
      "Epoch 147/500\n",
      "2583/2583 [==============================] - 2s 834us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 1.0153 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.96181\n",
      "Epoch 148/500\n",
      "2583/2583 [==============================] - 2s 825us/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.6382 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.96181\n",
      "Epoch 149/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.3666 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.96181\n",
      "Epoch 150/500\n",
      "2583/2583 [==============================] - 2s 817us/step - loss: 4.3131e-04 - acc: 1.0000 - val_loss: 0.4177 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.96181\n",
      "Epoch 151/500\n",
      "2583/2583 [==============================] - 2s 831us/step - loss: 4.5855e-04 - acc: 1.0000 - val_loss: 0.2925 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.96181\n",
      "Epoch 152/500\n",
      "2583/2583 [==============================] - 2s 825us/step - loss: 8.2836e-04 - acc: 1.0000 - val_loss: 0.3797 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.96181\n",
      "Epoch 153/500\n",
      "2583/2583 [==============================] - 2s 818us/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.2484 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.96181\n",
      "Epoch 154/500\n",
      "2583/2583 [==============================] - 2s 820us/step - loss: 0.0048 - acc: 0.9977 - val_loss: 0.3186 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.96181\n",
      "Epoch 155/500\n",
      "2583/2583 [==============================] - 2s 821us/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.5496 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.96181\n",
      "Epoch 156/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 0.0056 - acc: 0.9988 - val_loss: 1.1514 - val_acc: 0.8056\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.96181\n",
      "Epoch 157/500\n",
      "2583/2583 [==============================] - 2s 808us/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.3156 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.96181\n",
      "Epoch 158/500\n",
      "2583/2583 [==============================] - 2s 819us/step - loss: 8.3712e-04 - acc: 1.0000 - val_loss: 0.3524 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.96181\n",
      "Epoch 159/500\n",
      "2583/2583 [==============================] - 2s 823us/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.2546 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.96181\n",
      "Epoch 160/500\n",
      "2583/2583 [==============================] - 2s 822us/step - loss: 9.5447e-04 - acc: 0.9996 - val_loss: 0.4695 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.96181\n",
      "Epoch 161/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 9.8544e-04 - acc: 0.9996 - val_loss: 0.9343 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.96181\n",
      "Epoch 162/500\n",
      "2583/2583 [==============================] - 2s 828us/step - loss: 5.5096e-04 - acc: 1.0000 - val_loss: 0.3409 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.96181\n",
      "Epoch 163/500\n",
      "2583/2583 [==============================] - 2s 825us/step - loss: 8.2959e-04 - acc: 0.9996 - val_loss: 0.3881 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.96181\n",
      "Epoch 164/500\n",
      "2583/2583 [==============================] - 2s 826us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2235 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.96181\n",
      "Epoch 165/500\n",
      "2583/2583 [==============================] - 2s 835us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6337 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.96181\n",
      "Epoch 166/500\n",
      "1120/2583 [============>.................] - ETA: 1s - loss: 8.0015e-04 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-11db9171ba34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath=\"try7-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(trainX,trainY,batch_size = 32,epochs = 500,verbose = 1,validation_split = 0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmIBVW8gamZ7"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"try7-weights-improvement-87-0.96.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we evaluated our model on testing data and achieved an accuracy of 95.6 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-JqFJ_NwapV9",
    "outputId": "0f1b429f-538b-4a0e-85a4-50ebcd6a9493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 0s 932us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19681823286330064, 0.9561128498618505]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,testY,batch_size = 32,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bXbzOpzo4mX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_network2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
